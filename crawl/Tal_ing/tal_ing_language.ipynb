{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 탈잉 \n",
    "### 카테고리 : 외국어\n",
    "\n",
    "- 총 38 페이지\n",
    "- 페이지 당 15개 클래스\n",
    "- likes,link,location,number,price,teacher,title\n",
    "- 'location'의 경우 타 사이트와의 비교 후 tile과 합칠 예정 `'[' + location + ']' + title`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy, requests, re \n",
    "from scrapy.http import TextResponse\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로젝트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'taling_language', using template directory 'C:\\Users\\study\\anaconda3\\lib\\site-packages\\scrapy\\templates\\project', created in:\n",
      "    C:\\Users\\study\\Desktop\\git\\Tal_ing\\taling_language\n",
      "\n",
      "You can start your first spider with:\n",
      "    cd taling_language\n",
      "    scrapy genspider example example.com\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject taling_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200 https://taling.me/Home/Search/?cateMain=5>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req = requests.get(\"https://taling.me/Home/Search/?cateMain=5\")\n",
    "response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xpath 찾기 (page 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,\n",
       " ['/Talent/Detail/32461',\n",
       "  '/Talent/Detail/16353',\n",
       "  '/Talent/Detail/10668',\n",
       "  '/Talent/Detail/9522',\n",
       "  '/Talent/Detail/26419',\n",
       "  '/Talent/Detail/10408',\n",
       "  '/Talent/Detail/23850',\n",
       "  '/Talent/Detail/10570',\n",
       "  '/Talent/Detail/16620',\n",
       "  '/Talent/Detail/24263',\n",
       "  '/Talent/Detail/9947',\n",
       "  '/Talent/Detail/29581',\n",
       "  '/Talent/Detail/6024',\n",
       "  '/Talent/Detail/12119',\n",
       "  '/Talent/Detail/14395'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = response.xpath('//*[@id=\"top-space\"]/div/div/a/@href').extract()\n",
    "len(links), links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://taling.me/Talent/Detail/32461',\n",
       " 'https://taling.me/Talent/Detail/16353',\n",
       " 'https://taling.me/Talent/Detail/10668',\n",
       " 'https://taling.me/Talent/Detail/9522',\n",
       " 'https://taling.me/Talent/Detail/26419',\n",
       " 'https://taling.me/Talent/Detail/10408',\n",
       " 'https://taling.me/Talent/Detail/23850',\n",
       " 'https://taling.me/Talent/Detail/10570',\n",
       " 'https://taling.me/Talent/Detail/16620',\n",
       " 'https://taling.me/Talent/Detail/24263',\n",
       " 'https://taling.me/Talent/Detail/9947',\n",
       " 'https://taling.me/Talent/Detail/29581',\n",
       " 'https://taling.me/Talent/Detail/6024',\n",
       " 'https://taling.me/Talent/Detail/12119',\n",
       " 'https://taling.me/Talent/Detail/14395']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = list(map(response.urljoin, links))\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 강좌정보 xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200 https://taling.me/Talent/Detail/9522>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = links[3]\n",
    "req = requests.get(link)\n",
    "response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title, month(number of time), discount(x), price, category2, teacher, heart, likes, category1, link \n",
    "# 탈잉에서 category 분류는 페이지로 구분 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('탈잉',\n",
       " '[강남 신촌홍대 온라인 Live][3월 모집] 1:1 영어발음교정 : 리뷰가 보장하는 유일무이 전문 발음교정 ',\n",
       " 'J 튜터',\n",
       " '총 5회 10시간',\n",
       " '750,000원 /',\n",
       " '5.0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site = '탈잉'\n",
    "title = '[' + location + ']' + response.xpath('//*[@id=\"wrap\"]/div[2]/div[1]/section[1]/h1/text()')[0].extract()\n",
    "teacher = response.xpath('//*[@id=\"wrap\"]/div[2]/div[1]/section[1]/div/div[2]/em/text()')[0].extract()\n",
    "number = response.xpath('//*[@id=\"wrap\"]/div[2]/aside/div/p/span[2]/span/text()')[0].extract()\n",
    "s_price = response.xpath('//*[@id=\"wrap\"]/div[2]/div[3]/div/div[2]/p/span[2]/b/text()')[0].extract()\n",
    "contentment = response.xpath('//*[@id=\"wrap\"]/div[2]/div[1]/section[1]/div/div[2]/span/i[2]/text()')[0].extract()\n",
    "location = response.xpath('//*[@id=\"wrap\"]/div[2]/div[3]/div/div[2]/div/p[2]/text()')[0].extract().strip()\n",
    "#soldout = response.xpath('//*[@id=\"wrap\"]/div[2]/aside/div/ul[2]/li[2]/a/text').extract()\n",
    "\n",
    "site, title, teacher, number, s_price, contentment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting taling_language/taling_language/items.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile taling_language/taling_language/items.py\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class TalIngItem(scrapy.Item):\n",
    "    site = scrapy.Field()\n",
    "    title = scrapy.Field()\n",
    "    teacher = scrapy.Field()\n",
    "    number = scrapy.Field()\n",
    "    s_price = scrapy.Field()\n",
    "    contentment = scrapy.Field()\n",
    "    link = scrapy.Field()\n",
    "    soldout = scrapy.Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spider.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing taling_language/taling_language/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile taling_language/taling_language/spiders/spider.py\n",
    "import scrapy\n",
    "from tal_ing.items import TalIngItem\n",
    "\n",
    "\n",
    "class TalIngSpider(scrapy.Spider):\n",
    "    name = \"TalingLanguage\"\n",
    "    allow_domain = [\"taling.me\"]\n",
    "    pages = range(1, 38+1)\n",
    "    start_urls = [f\"https://taling.me/Home/Search/?page={page}&cateMain=5&cateSub=&region=&orderIdx=&query=&code=&org=&day=&time=&tType=&region=&regionMain=\" for page in pages]\n",
    "    \n",
    "    def parse(self, response):\n",
    "        links = response.xpath('//*[@id=\"top-space\"]/div/div/a/@href').extract()\n",
    "        links = list(map(response.urljoin, links))\n",
    "        for link in links:\n",
    "            #time.sleep(120) \n",
    "            yield scrapy.Request(link, callback=self.parse_content)\n",
    "    \n",
    "    def parse_content(self, response):\n",
    "        item = TalIngItem()\n",
    "        item['site'] = '탈잉'\n",
    "        item['category1'] = '외국어'\n",
    "        location = response.xpath('//*[@id=\"wrap\"]/div[2]/div[3]/div/div[2]/div/p[2]/text()')[0].extract().strip()\n",
    "        item[\"title\"] = '[' + location + ']' + response.xpath('//*[@id=\"wrap\"]/div[2]/div[1]/section[1]/h1/text()')[0].extract()\n",
    "        item[\"teacher\"] = response.xpath('//*[@id=\"wrap\"]/div[2]/div[1]/section[1]/div/div[2]/em/text()')[0].extract()\n",
    "        try:\n",
    "            item[\"number\"] = response.xpath('//*[@id=\"wrap\"]/div[2]/aside/div/p/span[2]/span/text()')[0].extract()\n",
    "        except:\n",
    "            item[\"number\"] = response.xpath('//*[@id=\"wrap\"]/div[2]/div[3]/div/div[2]/p/span[2]/span/text()')[0].extract()\n",
    "        item[\"price\"] = '총 ' + response.xpath('//*[@id=\"wrap\"]/div[2]/div[3]/div/div[2]/p/span[2]/b/text()')[0].extract().replace(' /', '')\n",
    "        try:\n",
    "            item[\"likes\"] = response.xpath('//*[@id=\"wrap\"]/div[2]/div[1]/section[1]/div/div[2]/span/i[2]/text()')[0].extract()\n",
    "        except:\n",
    "            item[\"likes\"] = \"(0)\"\n",
    "        soldout = response.xpath('//*[@id=\"wrap\"]/div[2]/aside/div/ul[2]/li[2]/a/text()').extract()\n",
    "        if soldout not in _:\n",
    "            pass\n",
    "        else:\n",
    "            item[\"soldout\"] = response.xpath('//*[@id=\"wrap\"]/div[2]/aside/div/ul[2]/li[2]/a/text()').extract()\n",
    "        \n",
    "        item[\"link\"] = response.url\n",
    "        #time.sleep(120)\n",
    "        yield item\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('탈잉',\n",
       " '[온라인 Live]★탈잉2020년매출1위★카톡으로 만나는1:1튜터★영어가 바뀌는습관, 내삶이 바뀌는아홉달',\n",
       " '방인영 튜터',\n",
       " '총 4회 24시간',\n",
       " '총 105,600원',\n",
       " '5.0',\n",
       " 'https://taling.me/Talent/Detail/16353')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages = range(1, 38+1)\n",
    "start_urls = [f\"https://taling.me/Home/Search/?page={page}&cateMain=5&cateSub=&region=&orderIdx=&query=&code=&org=&day=&time=&tType=&region=&regionMain=\" for page in pages]\n",
    "req = requests.get(start_urls[0])\n",
    "response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "\n",
    "links = response.xpath('//*[@id=\"top-space\"]/div/div/a/@href').extract()\n",
    "links = list(map(response.urljoin, links))\n",
    "req = requests.get(links[1])\n",
    "response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "\n",
    "site = '탈잉'\n",
    "location = response.xpath('//*[@id=\"wrap\"]/div[2]/div[3]/div/div[2]/div/p[2]/text()')[0].extract().strip()\n",
    "title = '[' + location + ']' + response.xpath('//*[@id=\"wrap\"]/div[2]/div[1]/section[1]/h1/text()')[0].extract()\n",
    "teacher = response.xpath('//*[@id=\"wrap\"]/div[2]/div[1]/section[1]/div/div[2]/em/text()')[0].extract()\n",
    "number = response.xpath('//*[@id=\"wrap\"]/div[2]/aside/div/p/span[2]/span/text()')[0].extract()\n",
    "price = '총 ' + response.xpath('//*[@id=\"wrap\"]/div[2]/div[3]/div/div[2]/p/span[2]/b/text()')[0].extract().replace(' /', '')\n",
    "likes = response.xpath('//*[@id=\"wrap\"]/div[2]/div[1]/section[1]/div/div[2]/span/i[2]/text()')[0].extract() \n",
    "#soldout= response.xpath('//*[@id=\"wrap\"]/div[2]/aside/div/ul[2]/li[2]/a/text()').extract()\n",
    "link = response.url\n",
    "\n",
    "site, title, teacher, number, price, contentment, link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\study\\\\Desktop\\\\git\\\\Tal_ing'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 7DCE-F2C1\n",
      "\n",
      " Directory of C:\\Users\\study\\Desktop\\git\\Tal_ing\\tal_ing\n",
      "\n",
      "2021-03-08  �삤�쟾 06:38    <DIR>          .\n",
      "2021-03-08  �삤�쟾 06:38    <DIR>          ..\n",
      "2021-03-08  �삤�쟾 06:38               257 scrapy.cfg\n",
      "2021-03-08  �삤�쟾 06:38    <DIR>          tal_ing\n",
      "               1 File(s)            257 bytes\n",
      "               3 Dir(s)  343,352,250,368 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls taling_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile run.sh\n",
    "cd C:\\Users\\study\\Desktop\\crawling\\tal_ing\n",
    "scrapy crawl TalingLanguage -o taling_language.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run.sh\n",
      "tal_ing\n",
      "tal_ing_hobby.ipynb\n",
      "tal_ing_language.ipynb\n",
      "taling_language\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\study\\Desktop\\git\\Tal_ing\\taling_language\n"
     ]
    }
   ],
   "source": [
    "%cd taling_language/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/study/Desktop/git/Tal_ing/taling_language\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "!/bin/bash run.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\study\\anaconda3\\lib\\site-packages\\scrapy\\commands\\__init__.py:131: ScrapyDeprecationWarning: ('The -t command line option is deprecated in favor of specifying the output format within the output URI. See the documentation of the -o and -O options for more information.',)\n",
      "  feeds = feed_process_params_from_cli(\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\study\\anaconda3\\Scripts\\scrapy-script.py\", line 10, in <module>\n",
      "    sys.exit(execute())\n",
      "  File \"C:\\Users\\study\\anaconda3\\lib\\site-packages\\scrapy\\cmdline.py\", line 144, in execute\n",
      "    cmd.crawler_process = CrawlerProcess(settings)\n",
      "  File \"C:\\Users\\study\\anaconda3\\lib\\site-packages\\scrapy\\crawler.py\", line 280, in __init__\n",
      "    super().__init__(settings)\n",
      "  File \"C:\\Users\\study\\anaconda3\\lib\\site-packages\\scrapy\\crawler.py\", line 152, in __init__\n",
      "    self.spider_loader = self._get_spider_loader(settings)\n",
      "  File \"C:\\Users\\study\\anaconda3\\lib\\site-packages\\scrapy\\crawler.py\", line 146, in _get_spider_loader\n",
      "    return loader_cls.from_settings(settings.frozencopy())\n",
      "  File \"C:\\Users\\study\\anaconda3\\lib\\site-packages\\scrapy\\spiderloader.py\", line 67, in from_settings\n",
      "    return cls(settings)\n",
      "  File \"C:\\Users\\study\\anaconda3\\lib\\site-packages\\scrapy\\spiderloader.py\", line 24, in __init__\n",
      "    self._load_all_spiders()\n",
      "  File \"C:\\Users\\study\\anaconda3\\lib\\site-packages\\scrapy\\spiderloader.py\", line 51, in _load_all_spiders\n",
      "    for module in walk_modules(name):\n",
      "  File \"C:\\Users\\study\\anaconda3\\lib\\site-packages\\scrapy\\utils\\misc.py\", line 89, in walk_modules\n",
      "    submod = import_module(fullpath)\n",
      "  File \"C:\\Users\\study\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\study\\Desktop\\git\\Tal_ing\\taling_language\\taling_language\\spiders\\spider.py\", line 2, in <module>\n",
      "    from tal_ing.items import TalIngItem\n",
      "ModuleNotFoundError: No module named 'tal_ing'\n"
     ]
    }
   ],
   "source": [
    "!scrapy crawl taling_language -o taling_language.csv -t csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tal_ing/taling_language.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-c45f9357b603>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tal_ing/taling_language.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tal_ing/taling_language.csv'"
     ]
    }
   ],
   "source": [
    "pd.read_csv(\"tal_ing/taling_language.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://taling.me/Home/Search/?page=1&cateMain=5&cateSub=&region=&orderIdx=&query=&code=&org=&day=&time=&tType=&region=&regionMain=',\n",
       " 'https://taling.me/Home/Search/?page=2&cateMain=5&cateSub=&region=&orderIdx=&query=&code=&org=&day=&time=&tType=&region=&regionMain=',\n",
       " 'https://taling.me/Home/Search/?page=3&cateMain=5&cateSub=&region=&orderIdx=&query=&code=&org=&day=&time=&tType=&region=&regionMain=',\n",
       " 'https://taling.me/Home/Search/?page=4&cateMain=5&cateSub=&region=&orderIdx=&query=&code=&org=&day=&time=&tType=&region=&regionMain=',\n",
       " 'https://taling.me/Home/Search/?page=5&cateMain=5&cateSub=&region=&orderIdx=&query=&code=&org=&day=&time=&tType=&region=&regionMain=',\n",
       " 'https://taling.me/Home/Search/?page=6&cateMain=5&cateSub=&region=&orderIdx=&query=&code=&org=&day=&time=&tType=&region=&regionMain=',\n",
       " 'https://taling.me/Home/Search/?page=7&cateMain=5&cateSub=&region=&orderIdx=&query=&code=&org=&day=&time=&tType=&region=&regionMain=',\n",
       " 'https://taling.me/Home/Search/?page=8&cateMain=5&cateSub=&region=&orderIdx=&query=&code=&org=&day=&time=&tType=&region=&regionMain=',\n",
       " 'https://taling.me/Home/Search/?page=9&cateMain=5&cateSub=&region=&orderIdx=&query=&code=&org=&day=&time=&tType=&region=&regionMain=',\n",
       " 'https://taling.me/Home/Search/?page=10&cateMain=5&cateSub=&region=&orderIdx=&query=&code=&org=&day=&time=&tType=&region=&regionMain=']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages = range(1, 38+1)\n",
    "start_urls = [f\"https://taling.me/Home/Search/?page={page}&cateMain=5&cateSub=&region=&orderIdx=&query=&code=&org=&day=&time=&tType=&region=&regionMain=\" for page in pages]\n",
    "start_urls[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
